[2020-01-27 15:00:56,324] WARN Exception causing close of session 0x1000048239f0006: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-01-27 15:01:03,439] INFO Expiring session 0x1000048239f0006, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:01:25,041] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-01-27 15:01:25,631] INFO starting (kafka.server.KafkaServer)
[2020-01-27 15:01:25,632] INFO Connecting to zookeeper on localhost:7777 (kafka.server.KafkaServer)
[2020-01-27 15:01:25,658] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:7777. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:01:31,346] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,346] INFO Client environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,346] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,346] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,346] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,346] INFO Client environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,346] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,346] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,346] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,346] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,362] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,377] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,377] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,377] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,377] INFO Client environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,377] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,377] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,377] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,393] INFO Initiating client connection, connectString=localhost:7777 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2ef3eef9 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:01:31,393] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-01-27 15:01:31,409] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-01-27 15:01:31,424] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:01:31,424] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:01:31,451] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:7777. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:01:31,457] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:10493, server: localhost/0:0:0:0:0:0:0:1:7777 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:01:31,523] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:7777, sessionid = 0x1000048239f0007, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:01:31,548] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:01:32,239] INFO Cluster ID = ZCBoZNizRZu31bPjkZIQkw (kafka.server.KafkaServer)
[2020-01-27 15:01:32,333] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:01:32,349] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:01:32,396] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:01:32,396] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:01:32,396] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:01:32,456] INFO Loading logs. (kafka.log.LogManager)
[2020-01-27 15:01:32,535] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 7 (kafka.log.Log)
[2020-01-27 15:01:32,540] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:32,564] INFO [ProducerStateManager partition=first-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:32,616] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:32,620] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 7 and log end offset 7 in 123 ms (kafka.log.Log)
[2020-01-27 15:01:32,652] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 6 (kafka.log.Log)
[2020-01-27 15:01:32,652] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:32,667] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:32,683] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:32,792] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:32,808] INFO [ProducerStateManager partition=first_topic-0] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:01:32,839] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 6 and log end offset 10 in 187 ms (kafka.log.Log)
[2020-01-27 15:01:32,855] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:01:32,855] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:32,855] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:32,855] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,027] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,042] INFO [ProducerStateManager partition=first_topic-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,042] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 5 in 203 ms (kafka.log.Log)
[2020-01-27 15:01:33,073] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:01:33,073] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,089] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,105] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,214] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,230] INFO [ProducerStateManager partition=first_topic-2] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-2\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,230] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 13 in 172 ms (kafka.log.Log)
[2020-01-27 15:01:33,245] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 1 (kafka.log.Log)
[2020-01-27 15:01:33,245] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,261] INFO [ProducerStateManager partition=second-topic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,277] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,277] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 1 and log end offset 1 in 47 ms (kafka.log.Log)
[2020-01-27 15:01:33,292] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:33,292] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,323] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,323] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:01:33,339] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:33,339] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,355] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,355] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:01:33,370] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:33,386] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,402] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,402] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-01-27 15:01:33,417] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:33,417] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,452] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,463] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2020-01-27 15:01:33,484] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:33,485] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,514] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,617] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,619] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,620] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 140 ms (kafka.log.Log)
[2020-01-27 15:01:33,632] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:33,633] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,644] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,700] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,703] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-10\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,712] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 82 ms (kafka.log.Log)
[2020-01-27 15:01:33,726] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:33,726] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,740] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,742] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:01:33,753] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:01:33,754] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index (kafka.log.Log)
[2020-01-27 15:01:33,765] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:01:33,766] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:01:33,779] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix .swap for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:01:33,787] ERROR [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Could not find offset index file corresponding to log file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-01-27 15:01:33,792] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,817] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 152 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,821] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 152 (kafka.log.Log)
[2020-01-27 15:01:33,822] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 152 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,831] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000152.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,838] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 156 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:33,991] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 156 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:33,998] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000156.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:01:34,000] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 2 segments, log start offset 0 and log end offset 156 in 250 ms (kafka.log.Log)
[2020-01-27 15:01:34,031] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,039] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,060] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,062] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2020-01-27 15:01:34,069] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,070] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,086] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,087] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:01:34,102] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,104] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,117] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,119] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:01:34,132] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,133] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,142] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,145] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:01:34,158] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,158] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,167] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,169] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:01:34,177] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,181] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,433] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 38039 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:34,545] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 38039 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,549] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-18\00000000000000038039.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:01:34,550] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 38039 in 377 ms (kafka.log.Log)
[2020-01-27 15:01:34,565] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,566] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,588] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,606] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2020-01-27 15:01:34,659] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,664] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,682] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,690] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2020-01-27 15:01:34,723] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,724] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,734] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,739] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:01:34,765] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,766] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,779] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,782] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:01:34,804] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,816] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,832] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,839] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2020-01-27 15:01:34,859] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,860] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,881] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,883] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-01-27 15:01:34,898] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,900] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,916] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,918] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-01-27 15:01:34,939] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,941] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,964] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:34,968] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2020-01-27 15:01:34,992] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:34,995] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,012] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,015] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:01:35,026] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,027] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,043] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,045] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-01-27 15:01:35,050] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,054] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,068] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,069] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:01:35,085] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,086] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,106] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 1596 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:35,554] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1596 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,559] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-29\00000000000000001596.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:01:35,561] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 1596 in 481 ms (kafka.log.Log)
[2020-01-27 15:01:35,579] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,580] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,591] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,593] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:01:35,601] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,601] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,614] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,616] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:01:35,630] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,631] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,643] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,644] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:01:35,649] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,652] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,663] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,665] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:01:35,671] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,672] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,684] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,686] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:01:35,693] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,694] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,707] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,709] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:01:35,714] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,714] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,724] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,727] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:01:35,733] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,734] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,747] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,749] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:01:35,755] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,759] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,770] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,773] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:01:35,778] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,780] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,789] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,791] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:01:35,804] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,805] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,825] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,827] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:01:35,831] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,833] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,843] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,845] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-01-27 15:01:35,850] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,855] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,864] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,866] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:01:35,874] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,875] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,887] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,890] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:01:35,897] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,897] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,911] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,912] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:01:35,918] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,919] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,932] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,934] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:01:35,942] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,942] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,954] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,955] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:01:35,970] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:35,971] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,984] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:35,985] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:01:36,003] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:36,004] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,021] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,022] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-01-27 15:01:36,026] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:36,027] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,039] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,042] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:01:36,160] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:36,187] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,214] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:01:36,398] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,399] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-48\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:01:36,402] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 322 ms (kafka.log.Log)
[2020-01-27 15:01:36,415] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:36,415] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,428] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,430] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:01:36,436] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:36,439] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,456] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,461] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:01:36,470] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:36,472] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,489] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,491] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:01:36,496] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:36,498] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,516] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,517] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-01-27 15:01:36,524] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:36,529] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,538] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,541] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:01:36,546] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:01:36,548] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,558] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:01:36,561] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:01:36,568] INFO Logs loading complete in 4112 ms. (kafka.log.LogManager)
[2020-01-27 15:01:36,590] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-01-27 15:01:36,592] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-01-27 15:01:36,984] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:497)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2267)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2267)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2267)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:604)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
	Suppressed: java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-01-27 15:01:37,070] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-01-27 15:01:37,114] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:01:37,148] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-01-27 15:01:37,155] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-01-27 15:01:37,199] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:01:37,199] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:01:37,202] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:01:37,202] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:01:37,241] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-01-27 15:01:37,246] INFO [ReplicaManager broker=0] Stopping serving replicas in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.server.ReplicaManager)
[2020-01-27 15:01:37,249] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:01:37,267] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka. (kafka.server.ReplicaManager)
[2020-01-27 15:01:37,270] INFO Stopping serving logs in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.log.LogManager)
[2020-01-27 15:01:37,275] ERROR Shutdown broker because all log dirs in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka have failed (kafka.log.LogManager)
[2020-01-27 15:01:37,638] WARN Exception causing close of session 0x1000048239f0007: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-01-27 15:01:45,428] INFO Expiring session 0x1000048239f0007, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:03:23,648] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-01-27 15:03:24,355] INFO starting (kafka.server.KafkaServer)
[2020-01-27 15:03:24,357] INFO Connecting to zookeeper on localhost:7777 (kafka.server.KafkaServer)
[2020-01-27 15:03:24,392] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:7777. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:03:29,127] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,128] INFO Client environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,128] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,128] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,129] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,129] INFO Client environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,133] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,134] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,134] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,135] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,135] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,136] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,141] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,141] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,143] INFO Client environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,143] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,144] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,145] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,152] INFO Initiating client connection, connectString=localhost:7777 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2ef3eef9 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:03:29,162] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-01-27 15:03:29,185] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-01-27 15:03:29,198] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:03:29,207] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:03:29,215] INFO Opening socket connection to server localhost/127.0.0.1:7777. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:03:29,222] INFO Socket connection established, initiating session, client: /127.0.0.1:10518, server: localhost/127.0.0.1:7777 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:03:29,498] INFO Session establishment complete on server localhost/127.0.0.1:7777, sessionid = 0x1000048239f0008, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:03:29,549] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:03:30,450] INFO Cluster ID = ZCBoZNizRZu31bPjkZIQkw (kafka.server.KafkaServer)
[2020-01-27 15:03:30,599] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:03:30,615] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:03:30,646] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:03:30,646] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:03:30,662] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:03:30,709] INFO Loading logs. (kafka.log.LogManager)
[2020-01-27 15:03:30,771] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 7 (kafka.log.Log)
[2020-01-27 15:03:30,771] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:30,787] INFO [ProducerStateManager partition=first-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:30,834] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:30,849] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 7 and log end offset 7 in 109 ms (kafka.log.Log)
[2020-01-27 15:03:30,880] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 6 (kafka.log.Log)
[2020-01-27 15:03:30,880] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:30,880] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:30,896] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:30,990] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:30,990] INFO [ProducerStateManager partition=first_topic-0] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,037] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 6 and log end offset 10 in 172 ms (kafka.log.Log)
[2020-01-27 15:03:31,052] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:03:31,052] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,052] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,068] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,130] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,130] INFO [ProducerStateManager partition=first_topic-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,130] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 5 in 93 ms (kafka.log.Log)
[2020-01-27 15:03:31,146] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:03:31,146] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,146] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,162] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,224] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,224] INFO [ProducerStateManager partition=first_topic-2] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-2\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,224] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 13 in 94 ms (kafka.log.Log)
[2020-01-27 15:03:31,240] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 1 (kafka.log.Log)
[2020-01-27 15:03:31,240] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,240] INFO [ProducerStateManager partition=second-topic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,240] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,255] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 1 and log end offset 1 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:31,255] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,255] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,271] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,271] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:31,271] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,271] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,287] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,287] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:31,287] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,287] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,302] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,302] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:31,302] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,302] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,318] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,318] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:31,318] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,318] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,334] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,488] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,493] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,497] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 179 ms (kafka.log.Log)
[2020-01-27 15:03:31,510] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,510] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,520] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,576] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,578] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-10\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,579] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 73 ms (kafka.log.Log)
[2020-01-27 15:03:31,587] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,589] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,597] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,600] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-01-27 15:03:31,610] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:03:31,614] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index (kafka.log.Log)
[2020-01-27 15:03:31,619] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:03:31,619] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:03:31,619] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix .swap for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:03:31,619] ERROR [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Could not find offset index file corresponding to log file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-01-27 15:03:31,635] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,666] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 152 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,666] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 152 (kafka.log.Log)
[2020-01-27 15:03:31,666] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 152 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,666] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000152.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,681] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 156 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,744] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 156 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,744] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000156.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:03:31,744] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 2 segments, log start offset 0 and log end offset 156 in 136 ms (kafka.log.Log)
[2020-01-27 15:03:31,760] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,775] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,775] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,791] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:03:31,791] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,791] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,806] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,806] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:31,822] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,822] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,838] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,838] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:31,853] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,853] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,869] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,869] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:31,885] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,885] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,885] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:31,885] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:31,900] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:31,900] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,150] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 38039 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:32,228] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 38039 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,228] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-18\00000000000000038039.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:03:32,228] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 38039 in 343 ms (kafka.log.Log)
[2020-01-27 15:03:32,228] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,228] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,244] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,244] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,260] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,260] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,275] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,275] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:32,275] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,275] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,291] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,291] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,306] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,306] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,306] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,306] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:32,322] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,322] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,322] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,338] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,338] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,338] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,338] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,353] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:32,353] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,353] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,353] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,353] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:32,369] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,369] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,369] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,369] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:32,385] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,385] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,385] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,385] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:32,400] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,400] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,400] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,400] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:32,400] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,400] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,416] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,416] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,416] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,416] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,445] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 1596 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:32,588] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1596 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,593] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-29\00000000000000001596.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:03:32,597] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 1596 in 181 ms (kafka.log.Log)
[2020-01-27 15:03:32,610] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,612] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,626] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,628] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:03:32,635] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,636] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,644] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,645] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-01-27 15:03:32,652] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,652] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,662] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,663] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:32,668] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,668] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,668] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,668] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-01-27 15:03:32,668] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,668] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,684] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,684] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,684] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,684] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,699] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,699] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:32,699] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,699] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,715] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,715] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,715] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,715] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,715] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,731] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,731] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,731] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,731] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,731] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:32,746] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,746] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,746] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,746] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:32,762] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,762] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,762] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,762] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,762] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,762] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,778] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,778] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,778] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,778] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,793] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,793] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:32,793] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,793] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,809] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,809] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,809] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,809] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,824] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,824] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:32,824] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,824] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,824] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,824] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:32,840] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,840] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,840] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,840] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:32,856] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,856] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,856] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,856] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:03:32,856] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,856] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,871] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,871] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:32,887] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,887] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,903] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,903] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-01-27 15:03:32,934] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:32,949] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:32,949] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:03:33,121] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,137] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-48\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:03:33,137] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 203 ms (kafka.log.Log)
[2020-01-27 15:03:33,153] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:33,153] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,153] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,168] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:03:33,168] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:33,168] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,168] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,168] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:33,184] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:33,184] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,184] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,184] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:33,199] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:33,199] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,199] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,199] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:33,215] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:33,215] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,215] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,215] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:33,231] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:03:33,231] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,231] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:03:33,231] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2020-01-27 15:03:33,246] INFO Logs loading complete in 2537 ms. (kafka.log.LogManager)
[2020-01-27 15:03:33,262] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-01-27 15:03:33,262] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-01-27 15:03:33,695] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:497)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2267)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2267)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2267)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:604)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
	Suppressed: java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-01-27 15:03:33,731] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-01-27 15:03:33,806] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-01-27 15:03:33,813] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-01-27 15:03:33,831] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:03:33,851] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:03:33,853] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:03:33,854] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:03:33,857] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:03:33,880] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-01-27 15:03:33,887] INFO [ReplicaManager broker=0] Stopping serving replicas in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.server.ReplicaManager)
[2020-01-27 15:03:33,913] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka. (kafka.server.ReplicaManager)
[2020-01-27 15:03:33,928] INFO Stopping serving logs in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.log.LogManager)
[2020-01-27 15:03:33,960] ERROR Shutdown broker because all log dirs in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka have failed (kafka.log.LogManager)
[2020-01-27 15:03:33,963] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:03:34,328] WARN Exception causing close of session 0x1000048239f0008: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-01-27 15:03:42,427] INFO Expiring session 0x1000048239f0008, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:05:53,549] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-01-27 15:05:54,132] INFO starting (kafka.server.KafkaServer)
[2020-01-27 15:05:54,133] INFO Connecting to zookeeper on localhost:7777 (kafka.server.KafkaServer)
[2020-01-27 15:05:54,156] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:7777. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:05:58,711] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,712] INFO Client environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,713] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,713] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,714] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,714] INFO Client environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,719] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,720] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,722] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,737] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,738] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,743] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,744] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,744] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,745] INFO Client environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,746] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,756] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,757] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,764] INFO Initiating client connection, connectString=localhost:7777 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2ef3eef9 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:05:58,772] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-01-27 15:05:58,789] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-01-27 15:05:58,801] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:05:58,804] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:05:58,821] INFO Opening socket connection to server localhost/127.0.0.1:7777. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:05:58,827] INFO Socket connection established, initiating session, client: /127.0.0.1:10567, server: localhost/127.0.0.1:7777 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:05:58,956] INFO Session establishment complete on server localhost/127.0.0.1:7777, sessionid = 0x1000048239f0009, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:05:58,986] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:05:59,842] INFO Cluster ID = ZCBoZNizRZu31bPjkZIQkw (kafka.server.KafkaServer)
[2020-01-27 15:05:59,932] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:05:59,951] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:05:59,989] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:05:59,989] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:05:59,993] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:06:00,069] INFO Loading logs. (kafka.log.LogManager)
[2020-01-27 15:06:00,146] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 7 (kafka.log.Log)
[2020-01-27 15:06:00,149] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,168] INFO [ProducerStateManager partition=first-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,222] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,235] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 7 and log end offset 7 in 125 ms (kafka.log.Log)
[2020-01-27 15:06:00,257] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 6 (kafka.log.Log)
[2020-01-27 15:06:00,259] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,266] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,286] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,446] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,456] INFO [ProducerStateManager partition=first_topic-0] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,482] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 6 and log end offset 10 in 230 ms (kafka.log.Log)
[2020-01-27 15:06:00,495] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:06:00,496] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,498] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,507] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,563] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,567] INFO [ProducerStateManager partition=first_topic-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,569] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 5 in 79 ms (kafka.log.Log)
[2020-01-27 15:06:00,581] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:06:00,581] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,584] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,598] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,746] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,753] INFO [ProducerStateManager partition=first_topic-2] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-2\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,756] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 13 in 177 ms (kafka.log.Log)
[2020-01-27 15:06:00,770] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 1 (kafka.log.Log)
[2020-01-27 15:06:00,774] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,792] INFO [ProducerStateManager partition=second-topic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:00,811] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,819] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 1 and log end offset 1 in 53 ms (kafka.log.Log)
[2020-01-27 15:06:00,837] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:00,838] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,870] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,877] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2020-01-27 15:06:00,900] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:00,900] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,908] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,910] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-01-27 15:06:00,919] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:00,920] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,934] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,935] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:06:00,947] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:00,947] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,958] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,961] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:06:00,970] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:00,971] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:00,997] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:01,068] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,076] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:06:01,081] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 114 ms (kafka.log.Log)
[2020-01-27 15:06:01,107] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:01,108] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,130] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:01,270] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,274] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-10\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:06:01,276] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 179 ms (kafka.log.Log)
[2020-01-27 15:06:01,291] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:01,293] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,308] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,310] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:06:01,317] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:06:01,320] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index (kafka.log.Log)
[2020-01-27 15:06:01,322] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:06:01,330] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:06:01,353] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix .swap for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:06:01,367] ERROR [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Could not find offset index file corresponding to log file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-01-27 15:06:01,367] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,392] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 152 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:01,398] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 152 (kafka.log.Log)
[2020-01-27 15:06:01,399] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 152 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,413] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000152.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:06:01,426] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 156 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:01,498] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 156 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,502] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000156.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:06:01,515] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 2 segments, log start offset 0 and log end offset 156 in 201 ms (kafka.log.Log)
[2020-01-27 15:06:01,565] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:01,580] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,597] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,599] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2020-01-27 15:06:01,608] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:01,610] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,625] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,626] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:06:01,633] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:01,636] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,648] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,650] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:06:01,660] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:01,661] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,669] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,674] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-01-27 15:06:01,682] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:01,682] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,691] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:01,693] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:06:01,705] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:01,706] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,181] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 38039 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:02,276] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 38039 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,279] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-18\00000000000000038039.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:06:02,281] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 38039 in 580 ms (kafka.log.Log)
[2020-01-27 15:06:02,294] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,294] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,310] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,313] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:06:02,327] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,329] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,344] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,347] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:06:02,359] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,360] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,369] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,374] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:06:02,384] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,385] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,398] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,400] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:06:02,413] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,414] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,432] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,439] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2020-01-27 15:06:02,450] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,451] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,464] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,465] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:06:02,477] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,477] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,486] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,490] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:06:02,497] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,497] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,506] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,509] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:06:02,519] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,520] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,532] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,534] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:06:02,545] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,546] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,553] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,555] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:06:02,567] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,568] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,581] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,583] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:06:02,592] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,593] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,611] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 1596 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:02,675] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1596 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,679] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-29\00000000000000001596.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:06:02,681] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 1596 in 93 ms (kafka.log.Log)
[2020-01-27 15:06:02,696] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,697] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,712] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,713] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:06:02,724] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,726] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,734] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,738] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:06:02,745] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,746] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,755] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,757] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:06:02,765] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,766] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,781] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,783] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:06:02,789] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,789] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,817] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,821] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2020-01-27 15:06:02,830] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,831] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,844] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,846] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:06:02,849] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,850] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,858] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,860] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-01-27 15:06:02,865] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,869] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,887] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,892] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-01-27 15:06:02,900] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,901] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,916] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,918] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:06:02,925] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,930] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,944] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,946] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-01-27 15:06:02,956] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,957] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,971] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,974] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-01-27 15:06:02,982] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:02,982] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,997] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:02,998] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:06:03,005] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,009] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,018] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,021] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:06:03,042] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,045] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,065] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,066] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:06:03,080] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,081] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,093] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,094] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:06:03,099] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,102] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,121] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,124] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-01-27 15:06:03,141] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,143] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,158] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,161] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-01-27 15:06:03,167] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,167] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,178] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,180] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:06:03,190] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,192] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,210] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,222] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2020-01-27 15:06:03,249] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,255] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,282] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,290] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2020-01-27 15:06:03,311] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,312] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,324] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:06:03,509] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,521] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-48\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:06:03,523] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 217 ms (kafka.log.Log)
[2020-01-27 15:06:03,542] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,544] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,563] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,572] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2020-01-27 15:06:03,590] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,611] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,633] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,640] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2020-01-27 15:06:03,658] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,662] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,680] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,682] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:06:03,696] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,708] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,729] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,737] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2020-01-27 15:06:03,748] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,752] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,764] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,766] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:06:03,774] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:06:03,777] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,788] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:06:03,789] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:06:03,796] INFO Logs loading complete in 3727 ms. (kafka.log.LogManager)
[2020-01-27 15:06:03,816] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-01-27 15:06:03,820] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-01-27 15:06:04,153] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:497)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2267)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2267)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2267)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:604)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
	Suppressed: java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-01-27 15:06:04,299] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-01-27 15:06:04,376] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-01-27 15:06:04,380] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:06:04,385] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-01-27 15:06:04,421] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:06:04,424] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:06:04,424] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:06:04,435] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:06:04,479] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-01-27 15:06:04,485] INFO [ReplicaManager broker=0] Stopping serving replicas in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.server.ReplicaManager)
[2020-01-27 15:06:04,499] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:06:04,523] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka. (kafka.server.ReplicaManager)
[2020-01-27 15:06:04,524] INFO Stopping serving logs in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.log.LogManager)
[2020-01-27 15:06:04,532] ERROR Shutdown broker because all log dirs in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka have failed (kafka.log.LogManager)
[2020-01-27 15:06:04,892] WARN Exception causing close of session 0x1000048239f0009: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-01-27 15:06:12,427] INFO Expiring session 0x1000048239f0009, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:08:59,256] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-01-27 15:08:59,877] INFO starting (kafka.server.KafkaServer)
[2020-01-27 15:08:59,878] INFO Connecting to zookeeper on localhost:7777 (kafka.server.KafkaServer)
[2020-01-27 15:08:59,901] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:7777. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:09:04,447] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,448] INFO Client environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,448] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,449] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,449] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,449] INFO Client environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,452] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,453] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,454] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,455] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,456] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,457] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,471] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,472] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,474] INFO Client environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,475] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,476] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,477] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,485] INFO Initiating client connection, connectString=localhost:7777 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2ef3eef9 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:09:04,494] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-01-27 15:09:04,512] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-01-27 15:09:04,523] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:09:04,527] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:09:04,537] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:7777. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:09:04,540] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:10606, server: localhost/0:0:0:0:0:0:0:1:7777 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:09:04,667] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:7777, sessionid = 0x1000048239f000a, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:09:04,687] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:09:05,835] INFO Cluster ID = ZCBoZNizRZu31bPjkZIQkw (kafka.server.KafkaServer)
[2020-01-27 15:09:05,927] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:09:05,949] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:09:05,989] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:09:05,990] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:09:06,002] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:09:06,058] INFO Loading logs. (kafka.log.LogManager)
[2020-01-27 15:09:06,138] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 7 (kafka.log.Log)
[2020-01-27 15:09:06,142] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,181] INFO [ProducerStateManager partition=first-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,280] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,301] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 7 and log end offset 7 in 201 ms (kafka.log.Log)
[2020-01-27 15:09:06,355] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 6 (kafka.log.Log)
[2020-01-27 15:09:06,358] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,371] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,395] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,479] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,482] INFO [ProducerStateManager partition=first_topic-0] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,497] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 6 and log end offset 10 in 148 ms (kafka.log.Log)
[2020-01-27 15:09:06,507] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:09:06,508] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,512] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,530] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,677] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,684] INFO [ProducerStateManager partition=first_topic-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,686] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 5 in 181 ms (kafka.log.Log)
[2020-01-27 15:09:06,701] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:09:06,702] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,705] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,719] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,786] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,789] INFO [ProducerStateManager partition=first_topic-2] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-2\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,791] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 13 in 94 ms (kafka.log.Log)
[2020-01-27 15:09:06,807] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 1 (kafka.log.Log)
[2020-01-27 15:09:06,808] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,813] INFO [ProducerStateManager partition=second-topic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:06,825] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,829] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 1 and log end offset 1 in 26 ms (kafka.log.Log)
[2020-01-27 15:09:06,847] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:06,848] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,862] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,864] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:09:06,880] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:06,881] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,889] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,891] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:09:06,903] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:06,903] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,915] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,916] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:09:06,931] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:06,932] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,942] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,945] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:09:06,961] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:06,963] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:06,974] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:07,041] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,047] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:09:07,050] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 93 ms (kafka.log.Log)
[2020-01-27 15:09:07,078] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:07,079] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,094] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:07,151] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,153] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-10\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:09:07,155] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 84 ms (kafka.log.Log)
[2020-01-27 15:09:07,168] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:07,168] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,180] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,181] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:09:07,192] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:09:07,193] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index (kafka.log.Log)
[2020-01-27 15:09:07,203] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:09:07,203] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:09:07,206] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix .swap for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:09:07,220] ERROR [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Could not find offset index file corresponding to log file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-01-27 15:09:07,224] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,249] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 152 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:07,253] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 152 (kafka.log.Log)
[2020-01-27 15:09:07,254] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 152 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,263] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000152.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:09:07,271] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 156 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:07,333] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 156 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,335] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000156.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:09:07,337] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 2 segments, log start offset 0 and log end offset 156 in 150 ms (kafka.log.Log)
[2020-01-27 15:09:07,353] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:07,354] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,367] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,369] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:09:07,379] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:07,382] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,398] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,402] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:09:07,418] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:07,418] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,432] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,434] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:09:07,451] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:07,451] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,463] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,467] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:09:07,485] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:07,490] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,504] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:07,517] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2020-01-27 15:09:07,535] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:07,539] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,140] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 38039 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:08,302] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 38039 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,309] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-18\00000000000000038039.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:09:08,317] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 38039 in 790 ms (kafka.log.Log)
[2020-01-27 15:09:08,351] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,352] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,370] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,371] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2020-01-27 15:09:08,383] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,383] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,398] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,400] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:09:08,414] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,416] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,425] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,434] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:09:08,450] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,451] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,465] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,467] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-01-27 15:09:08,480] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,481] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,497] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,501] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:09:08,510] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,512] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,523] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,527] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:09:08,547] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,548] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,560] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,563] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-01-27 15:09:08,572] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,573] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,582] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,585] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:09:08,597] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,597] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,609] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,611] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:09:08,623] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,624] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,646] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,648] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-01-27 15:09:08,652] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,656] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,668] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,669] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:09:08,680] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,681] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,699] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 1596 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:08,924] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1596 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,927] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-29\00000000000000001596.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:09:08,930] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 1596 in 256 ms (kafka.log.Log)
[2020-01-27 15:09:08,966] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:08,969] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:08,993] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,003] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2020-01-27 15:09:09,017] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,019] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,035] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,138] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 124 ms (kafka.log.Log)
[2020-01-27 15:09:09,149] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,150] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,161] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,163] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:09:09,170] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,171] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,188] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,193] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-01-27 15:09:09,202] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,205] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,225] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,227] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:09:09,243] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,247] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,261] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,263] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-01-27 15:09:09,271] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,272] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,288] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,289] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:09:09,296] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,296] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,307] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,309] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:09:09,336] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,337] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,351] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,353] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:09:09,365] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,369] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,382] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,384] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:09:09,398] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,399] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,410] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,411] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-01-27 15:09:09,422] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,424] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,441] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,444] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:09:09,463] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,464] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,480] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,483] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-01-27 15:09:09,493] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,496] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,512] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,514] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-01-27 15:09:09,521] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,525] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,541] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,544] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:09:09,551] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,552] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,567] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,569] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:09:09,581] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,582] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,595] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,597] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:09:09,610] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,611] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,624] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,627] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-01-27 15:09:09,646] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,647] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,668] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,671] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2020-01-27 15:09:09,681] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,684] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,699] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,704] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-01-27 15:09:09,714] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,714] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,730] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:09:09,796] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,799] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-48\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:09:09,800] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 88 ms (kafka.log.Log)
[2020-01-27 15:09:09,814] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,815] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,831] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,834] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:09:09,848] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,849] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,866] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,868] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:09:09,883] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,887] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,904] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,906] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:09:09,915] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,918] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,930] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,931] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:09:09,938] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,942] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,956] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,958] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:09:09,972] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:09:09,974] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,988] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:09:09,992] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-01-27 15:09:10,001] INFO Logs loading complete in 3943 ms. (kafka.log.LogManager)
[2020-01-27 15:09:10,027] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-01-27 15:09:10,030] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-01-27 15:09:10,539] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:497)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2267)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2267)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2267)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:604)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
	Suppressed: java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-01-27 15:09:10,696] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:09:10,758] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-01-27 15:09:10,810] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-01-27 15:09:10,816] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-01-27 15:09:10,853] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:09:10,870] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:09:10,872] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:09:10,869] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:09:10,920] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-01-27 15:09:10,927] INFO [ReplicaManager broker=0] Stopping serving replicas in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.server.ReplicaManager)
[2020-01-27 15:09:10,937] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:09:10,965] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka. (kafka.server.ReplicaManager)
[2020-01-27 15:09:10,966] INFO Stopping serving logs in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.log.LogManager)
[2020-01-27 15:09:10,975] ERROR Shutdown broker because all log dirs in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka have failed (kafka.log.LogManager)
[2020-01-27 15:09:11,372] WARN Exception causing close of session 0x1000048239f000a: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-01-27 15:09:18,428] INFO Expiring session 0x1000048239f000a, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:39,987] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:11:40,002] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:11:40,002] INFO clientPortAddress is 0.0.0.0/0.0.0.0:7777 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:11:40,002] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:11:40,002] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-01-27 15:11:40,002] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-01-27 15:11:40,002] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-01-27 15:11:40,002] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-01-27 15:11:40,002] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-01-27 15:11:40,033] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:11:40,033] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:11:40,033] INFO clientPortAddress is 0.0.0.0/0.0.0.0:7777 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:11:40,033] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:11:40,033] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-01-27 15:11:40,033] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-01-27 15:11:44,590] INFO Server environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,591] INFO Server environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,592] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,592] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,593] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,594] INFO Server environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,597] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,598] INFO Server environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,599] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,599] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,601] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,605] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,607] INFO Server environment:user.name=Administrator (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,608] INFO Server environment:user.home=C:\Users\Administrator (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,609] INFO Server environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,610] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,611] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,612] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,617] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,617] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,620] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2 snapdir E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:11:44,649] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-01-27 15:11:44,677] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-01-27 15:11:44,682] INFO binding to port 0.0.0.0/0.0.0.0:7777 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-01-27 15:11:44,700] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-01-27 15:11:44,706] INFO Reading snapshot E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2\snapshot.d7 (org.apache.zookeeper.server.persistence.FileSnap)
[2020-01-27 15:11:44,746] INFO Snapshotting: 0x195 to E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2\snapshot.195 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-01-27 15:11:44,772] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-01-27 15:12:06,449] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-01-27 15:12:07,147] INFO starting (kafka.server.KafkaServer)
[2020-01-27 15:12:07,148] INFO Connecting to zookeeper on localhost:7777 (kafka.server.KafkaServer)
[2020-01-27 15:12:07,173] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:7777. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:12:11,728] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,729] INFO Client environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,729] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,729] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,729] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,730] INFO Client environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,732] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,733] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,733] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,734] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,735] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,736] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,736] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,737] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,738] INFO Client environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,755] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,756] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,759] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,770] INFO Initiating client connection, connectString=localhost:7777 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2ef3eef9 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:12:11,789] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-01-27 15:12:11,819] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-01-27 15:12:11,836] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:12:11,839] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:12:11,853] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:7777. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:12:11,858] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:10652, server: localhost/0:0:0:0:0:0:0:1:7777 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:12:11,873] INFO Creating new log file: log.196 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-01-27 15:12:12,047] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:7777, sessionid = 0x100011cf29a0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:12:12,085] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:12:13,124] INFO Cluster ID = ZCBoZNizRZu31bPjkZIQkw (kafka.server.KafkaServer)
[2020-01-27 15:12:13,218] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:12:13,240] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:12:13,283] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:12:13,283] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:12:13,297] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:12:13,357] INFO Loading logs. (kafka.log.LogManager)
[2020-01-27 15:12:13,438] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 7 (kafka.log.Log)
[2020-01-27 15:12:13,443] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:13,462] INFO [ProducerStateManager partition=first-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:13,526] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:13,537] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 7 and log end offset 7 in 136 ms (kafka.log.Log)
[2020-01-27 15:12:13,566] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 6 (kafka.log.Log)
[2020-01-27 15:12:13,569] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:13,574] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:13,590] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:13,897] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:13,907] INFO [ProducerStateManager partition=first_topic-0] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:12:13,943] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 6 and log end offset 10 in 382 ms (kafka.log.Log)
[2020-01-27 15:12:13,957] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:12:13,958] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:13,960] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:13,968] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:14,095] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,104] INFO [ProducerStateManager partition=first_topic-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:12:14,108] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 5 in 154 ms (kafka.log.Log)
[2020-01-27 15:12:14,149] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:12:14,156] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,164] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:14,193] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:14,272] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,276] INFO [ProducerStateManager partition=first_topic-2] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-2\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:12:14,279] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 13 in 140 ms (kafka.log.Log)
[2020-01-27 15:12:14,302] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 1 (kafka.log.Log)
[2020-01-27 15:12:14,303] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,309] INFO [ProducerStateManager partition=second-topic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:14,327] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,335] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 1 and log end offset 1 in 36 ms (kafka.log.Log)
[2020-01-27 15:12:14,357] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:14,358] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,392] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,396] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2020-01-27 15:12:14,424] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:14,425] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,443] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,450] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:12:14,476] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:14,479] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,496] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,499] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-01-27 15:12:14,508] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:14,509] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,521] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,523] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:12:14,536] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:14,536] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,546] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:14,629] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,634] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:12:14,638] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 109 ms (kafka.log.Log)
[2020-01-27 15:12:14,669] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:14,670] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,705] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:14,866] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,872] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-10\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:12:14,877] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 215 ms (kafka.log.Log)
[2020-01-27 15:12:14,901] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:14,902] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,930] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:14,934] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2020-01-27 15:12:14,945] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:12:14,946] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index (kafka.log.Log)
[2020-01-27 15:12:14,956] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:12:14,957] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:12:14,968] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix .swap for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:12:14,976] ERROR [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Could not find offset index file corresponding to log file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-01-27 15:12:14,978] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,009] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 152 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:15,014] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 152 (kafka.log.Log)
[2020-01-27 15:12:15,021] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 152 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,024] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000152.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:12:15,030] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 156 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:15,122] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 156 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,127] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000156.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:12:15,137] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 2 segments, log start offset 0 and log end offset 156 in 197 ms (kafka.log.Log)
[2020-01-27 15:12:15,174] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:15,176] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,200] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,202] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2020-01-27 15:12:15,207] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:15,209] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,222] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,223] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:12:15,232] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:15,234] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,246] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,248] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:12:15,272] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:15,273] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,283] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,285] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:12:15,296] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:15,296] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,322] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,325] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2020-01-27 15:12:15,337] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:15,338] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:15,812] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 38039 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:16,010] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 38039 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,017] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-18\00000000000000038039.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:12:16,023] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 38039 in 689 ms (kafka.log.Log)
[2020-01-27 15:12:16,053] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,054] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,072] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,074] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-01-27 15:12:16,085] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,086] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,097] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,098] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:12:16,108] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,108] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,120] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,123] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:12:16,135] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,136] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,149] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,150] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:12:16,158] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,162] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,181] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,182] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:12:16,186] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,187] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,195] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,197] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-01-27 15:12:16,210] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,211] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,223] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,224] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:12:16,233] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,236] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,245] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,248] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:12:16,257] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,258] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,268] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,269] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:12:16,275] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,280] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,289] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,291] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:12:16,298] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,302] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,312] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,314] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:12:16,320] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,321] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,338] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 1596 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:16,591] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1596 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,595] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-29\00000000000000001596.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:12:16,598] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 1596 in 281 ms (kafka.log.Log)
[2020-01-27 15:12:16,620] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,622] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,650] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,654] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2020-01-27 15:12:16,661] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,664] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,674] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,676] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:12:16,685] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,685] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,695] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,696] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:12:16,706] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,707] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,721] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,723] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:12:16,731] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,731] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,744] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,746] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:12:16,759] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,760] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,775] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,779] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-01-27 15:12:16,790] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,792] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,807] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,810] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:12:16,822] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,823] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,841] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,845] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:12:16,867] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,868] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,882] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,887] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-01-27 15:12:16,901] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,902] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,917] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,919] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-01-27 15:12:16,933] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,933] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,954] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:16,958] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-01-27 15:12:16,975] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:16,977] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,004] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,011] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2020-01-27 15:12:17,031] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,037] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,050] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,052] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-01-27 15:12:17,066] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,067] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,086] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,090] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:12:17,103] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,105] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,123] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,126] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:12:17,147] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,148] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,163] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,170] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:12:17,183] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,184] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,197] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,199] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-01-27 15:12:17,208] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,209] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,228] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,230] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-01-27 15:12:17,235] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,236] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,248] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,254] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:12:17,266] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,268] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,291] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,294] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2020-01-27 15:12:17,309] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,310] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,322] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:12:17,394] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,396] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-48\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:12:17,398] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 94 ms (kafka.log.Log)
[2020-01-27 15:12:17,412] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,412] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,430] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,431] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-01-27 15:12:17,435] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,435] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,446] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,447] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-01-27 15:12:17,457] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,457] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,474] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,477] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:12:17,481] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,482] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,490] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,492] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-01-27 15:12:17,500] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,504] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,516] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,518] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:12:17,525] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:12:17,526] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,538] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:12:17,540] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:12:17,550] INFO Logs loading complete in 4192 ms. (kafka.log.LogManager)
[2020-01-27 15:12:17,576] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-01-27 15:12:17,582] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-01-27 15:12:18,009] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:497)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2267)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2267)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2267)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:604)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
	Suppressed: java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-01-27 15:12:18,082] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-01-27 15:12:18,156] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-01-27 15:12:18,164] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-01-27 15:12:18,165] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:12:18,200] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:12:18,204] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:12:18,204] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:12:18,213] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:12:18,265] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-01-27 15:12:18,279] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:12:18,282] INFO [ReplicaManager broker=0] Stopping serving replicas in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.server.ReplicaManager)
[2020-01-27 15:12:18,302] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka. (kafka.server.ReplicaManager)
[2020-01-27 15:12:18,305] INFO Stopping serving logs in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.log.LogManager)
[2020-01-27 15:12:18,321] ERROR Shutdown broker because all log dirs in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka have failed (kafka.log.LogManager)
[2020-01-27 15:12:18,718] WARN Exception causing close of session 0x100011cf29a0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-01-27 15:12:24,427] INFO Expiring session 0x100011cf29a0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:44:56,792] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:44:56,826] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:44:56,826] INFO clientPortAddress is 0.0.0.0/0.0.0.0:7777 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:44:56,826] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:44:56,842] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-01-27 15:44:56,842] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-01-27 15:44:56,842] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-01-27 15:44:56,842] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-01-27 15:44:56,846] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-01-27 15:44:56,892] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:44:56,892] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:44:56,892] INFO clientPortAddress is 0.0.0.0/0.0.0.0:7777 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:44:56,892] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:44:56,892] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-01-27 15:44:56,923] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-01-27 15:45:02,261] INFO Server environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,261] INFO Server environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,261] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,261] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,261] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,277] INFO Server environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,277] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,292] INFO Server environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,292] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,308] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,308] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,308] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,308] INFO Server environment:user.name=Administrator (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,308] INFO Server environment:user.home=C:\Users\Administrator (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,308] INFO Server environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,308] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,308] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,308] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,324] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,324] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:02,324] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2 snapdir E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:45:03,007] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-01-27 15:45:03,185] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-01-27 15:45:03,201] INFO binding to port 0.0.0.0/0.0.0.0:7777 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-01-27 15:45:03,523] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-01-27 15:45:03,839] INFO Reading snapshot E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2\snapshot.195 (org.apache.zookeeper.server.persistence.FileSnap)
[2020-01-27 15:45:04,354] INFO Snapshotting: 0x1a4 to E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2\snapshot.1a4 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-01-27 15:45:04,484] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-01-27 15:45:19,391] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-01-27 15:45:20,483] INFO starting (kafka.server.KafkaServer)
[2020-01-27 15:45:20,485] INFO Connecting to zookeeper on localhost:7777 (kafka.server.KafkaServer)
[2020-01-27 15:45:20,541] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:7777. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:45:25,174] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,174] INFO Client environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,174] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,174] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,174] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,174] INFO Client environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,189] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,189] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,189] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,189] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,189] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,205] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,205] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,205] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,205] INFO Client environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,205] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,205] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,205] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,205] INFO Initiating client connection, connectString=localhost:7777 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2ef3eef9 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:45:25,267] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-01-27 15:45:25,283] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-01-27 15:45:25,314] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:45:25,330] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:45:25,435] INFO Opening socket connection to server localhost/127.0.0.1:7777. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:45:25,435] INFO Socket connection established, initiating session, client: /127.0.0.1:3370, server: localhost/127.0.0.1:7777 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:45:25,467] INFO Creating new log file: log.1a5 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-01-27 15:45:25,566] INFO Session establishment complete on server localhost/127.0.0.1:7777, sessionid = 0x100001b0ae50000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:45:25,582] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:45:26,779] INFO Cluster ID = ZCBoZNizRZu31bPjkZIQkw (kafka.server.KafkaServer)
[2020-01-27 15:45:26,945] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:45:26,969] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:45:27,040] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:45:27,040] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:45:27,045] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:45:27,268] INFO Loading logs. (kafka.log.LogManager)
[2020-01-27 15:45:27,442] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 7 (kafka.log.Log)
[2020-01-27 15:45:27,451] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:27,484] INFO [ProducerStateManager partition=first-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:27,591] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:27,604] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 7 and log end offset 7 in 262 ms (kafka.log.Log)
[2020-01-27 15:45:27,628] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 6 (kafka.log.Log)
[2020-01-27 15:45:27,630] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:27,635] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:27,650] INFO [ProducerStateManager partition=first_topic-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:27,787] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:27,790] INFO [ProducerStateManager partition=first_topic-0] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:45:27,808] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 6 and log end offset 10 in 184 ms (kafka.log.Log)
[2020-01-27 15:45:27,819] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:45:27,820] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:27,823] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:27,865] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:27,930] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:27,933] INFO [ProducerStateManager partition=first_topic-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:45:27,936] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 5 in 121 ms (kafka.log.Log)
[2020-01-27 15:45:27,943] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:45:27,944] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:27,946] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:27,979] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,146] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,151] INFO [ProducerStateManager partition=first_topic-2] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-2\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,152] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 13 in 212 ms (kafka.log.Log)
[2020-01-27 15:45:28,159] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 1 (kafka.log.Log)
[2020-01-27 15:45:28,159] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,162] INFO [ProducerStateManager partition=second-topic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,171] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,173] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 1 and log end offset 1 in 17 ms (kafka.log.Log)
[2020-01-27 15:45:28,181] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,182] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,197] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,200] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:45:28,211] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,212] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,222] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,224] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:45:28,231] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,232] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,242] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,244] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:45:28,254] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,255] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,263] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,264] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-01-27 15:45:28,274] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,275] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,286] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,351] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,353] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,354] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 83 ms (kafka.log.Log)
[2020-01-27 15:45:28,363] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,364] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,412] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,555] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,557] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-10\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,559] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 199 ms (kafka.log.Log)
[2020-01-27 15:45:28,571] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,574] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,592] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,595] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:45:28,609] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:45:28,611] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index (kafka.log.Log)
[2020-01-27 15:45:28,616] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:45:28,618] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:45:28,622] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix .swap for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:45:28,638] ERROR [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Could not find offset index file corresponding to log file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-01-27 15:45:28,641] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,676] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 152 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,685] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 152 (kafka.log.Log)
[2020-01-27 15:45:28,690] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 152 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,695] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000152.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,728] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 156 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,805] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 156 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,809] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000156.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:45:28,812] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 2 segments, log start offset 0 and log end offset 156 in 206 ms (kafka.log.Log)
[2020-01-27 15:45:28,824] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,827] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,847] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,852] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:45:28,862] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,863] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,875] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,877] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:45:28,888] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,888] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,900] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,903] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:45:28,910] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,911] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,921] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,923] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:28,931] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,932] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,942] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:28,943] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:45:28,952] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:28,952] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,254] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 38039 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:29,368] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 38039 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,372] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-18\00000000000000038039.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:45:29,374] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 38039 in 426 ms (kafka.log.Log)
[2020-01-27 15:45:29,388] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,392] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,399] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,399] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-01-27 15:45:29,415] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,415] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,430] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,430] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:45:29,430] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,430] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,446] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,446] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:29,462] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,462] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,477] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,477] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:45:29,493] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,493] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,509] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,509] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-01-27 15:45:29,509] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,509] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,524] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,524] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:45:29,540] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,540] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,540] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,555] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:45:29,555] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,555] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,571] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,571] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:29,587] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,587] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,587] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,587] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:29,602] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,602] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,618] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,618] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:29,618] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,618] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,634] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,634] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:29,634] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,634] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,680] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 1596 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:29,790] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1596 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,805] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-29\00000000000000001596.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:45:29,805] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 1596 in 171 ms (kafka.log.Log)
[2020-01-27 15:45:29,805] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,805] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,821] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,821] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:29,837] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,837] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,852] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,852] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:45:29,868] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,868] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,884] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,899] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2020-01-27 15:45:29,899] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,915] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,915] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,930] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:45:29,930] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,930] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,946] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,946] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:29,962] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,962] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,977] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:29,977] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:45:29,993] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:29,993] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,009] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,009] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-01-27 15:45:30,024] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,024] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,032] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,032] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:45:30,063] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,066] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,085] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,088] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:45:30,097] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,097] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,097] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,112] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:45:30,112] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,112] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,128] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,128] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:30,144] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,144] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,159] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,159] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:45:30,159] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,159] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,175] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,175] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:30,175] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,175] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,191] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,191] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:30,206] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,206] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,206] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,206] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:45:30,222] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,222] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,222] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,237] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:45:30,237] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,237] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,253] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,253] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:30,253] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,253] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,269] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,269] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:30,269] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,269] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,284] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,284] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:45:30,300] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,300] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,300] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,316] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-01-27 15:45:30,316] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,316] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,331] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:45:30,412] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,416] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-48\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:45:30,417] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 101 ms (kafka.log.Log)
[2020-01-27 15:45:30,424] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,425] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,436] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,438] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:45:30,445] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,445] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,447] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,447] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-01-27 15:45:30,462] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,462] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,478] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,478] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:45:30,478] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,478] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,494] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,494] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:30,494] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,494] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,509] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,525] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:45:30,525] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:45:30,525] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,541] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:45:30,541] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:45:30,541] INFO Logs loading complete in 3273 ms. (kafka.log.LogManager)
[2020-01-27 15:45:30,572] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-01-27 15:45:30,572] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-01-27 15:45:31,435] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:497)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2267)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2267)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2267)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:604)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
	Suppressed: java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-01-27 15:45:31,622] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:45:31,778] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:45:31,884] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:45:31,977] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:45:32,102] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:45:32,259] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-01-27 15:45:32,307] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:45:32,390] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-01-27 15:45:32,393] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-01-27 15:45:32,498] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:45:32,508] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:45:32,510] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:45:32,510] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:45:32,510] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:45:32,531] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-01-27 15:45:32,536] INFO [ReplicaManager broker=0] Stopping serving replicas in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.server.ReplicaManager)
[2020-01-27 15:45:32,588] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka. (kafka.server.ReplicaManager)
[2020-01-27 15:45:32,596] INFO Stopping serving logs in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.log.LogManager)
[2020-01-27 15:45:32,621] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:45:32,633] ERROR Shutdown broker because all log dirs in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka have failed (kafka.log.LogManager)
[2020-01-27 15:45:33,005] WARN Exception causing close of session 0x100001b0ae50000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-01-27 15:45:41,147] INFO Expiring session 0x100001b0ae50000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:50:51,268] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-01-27 15:50:52,006] INFO starting (kafka.server.KafkaServer)
[2020-01-27 15:50:52,007] INFO Connecting to zookeeper on localhost:7777 (kafka.server.KafkaServer)
[2020-01-27 15:50:52,031] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:7777. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:50:56,572] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,573] INFO Client environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,574] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,575] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,575] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,575] INFO Client environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,581] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,583] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,609] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,612] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,616] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,618] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,622] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,630] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,633] INFO Client environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,634] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,642] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,645] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,657] INFO Initiating client connection, connectString=localhost:7777 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2ef3eef9 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:50:56,669] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-01-27 15:50:56,689] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-01-27 15:50:56,702] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:50:56,709] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:50:56,728] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:7777. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:50:56,734] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:3652, server: localhost/0:0:0:0:0:0:0:1:7777 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:50:56,885] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:7777, sessionid = 0x100001b0ae50001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:50:56,905] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:50:58,062] INFO Cluster ID = ZCBoZNizRZu31bPjkZIQkw (kafka.server.KafkaServer)
[2020-01-27 15:50:58,166] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:50:58,191] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:50:58,237] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:50:58,237] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:50:58,241] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:50:58,300] INFO Loading logs. (kafka.log.LogManager)
[2020-01-27 15:50:58,387] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 7 (kafka.log.Log)
[2020-01-27 15:50:58,392] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,417] INFO [ProducerStateManager partition=first-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:50:58,475] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,487] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 7 and log end offset 7 in 139 ms (kafka.log.Log)
[2020-01-27 15:50:58,509] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:50:58,513] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,531] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:50:58,548] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-01-27 15:50:58,659] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,668] INFO [ProducerStateManager partition=first_topic-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:50:58,693] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 5 in 187 ms (kafka.log.Log)
[2020-01-27 15:50:58,713] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:50:58,714] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,720] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:50:58,738] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-01-27 15:50:58,838] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,845] INFO [ProducerStateManager partition=first_topic-2] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-2\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:50:58,847] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 13 in 139 ms (kafka.log.Log)
[2020-01-27 15:50:58,867] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 1 (kafka.log.Log)
[2020-01-27 15:50:58,868] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,872] INFO [ProducerStateManager partition=second-topic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-01-27 15:50:58,888] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,892] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 1 and log end offset 1 in 28 ms (kafka.log.Log)
[2020-01-27 15:50:58,908] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:58,909] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,922] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,924] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:50:58,935] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:58,936] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,948] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,950] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:50:58,959] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:58,960] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,979] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:58,981] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-01-27 15:50:58,999] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:58,999] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,010] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:50:59,147] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,151] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:50:59,156] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 164 ms (kafka.log.Log)
[2020-01-27 15:50:59,189] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:59,190] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,224] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:50:59,350] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,355] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-10\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:50:59,360] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 180 ms (kafka.log.Log)
[2020-01-27 15:50:59,393] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:59,397] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,419] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,421] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2020-01-27 15:50:59,432] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:50:59,433] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.index (kafka.log.Log)
[2020-01-27 15:50:59,436] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Found file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2020-01-27 15:50:59,441] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix  for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:50:59,446] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Deleting index files with suffix .swap for baseFile E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log (kafka.log.Log)
[2020-01-27 15:50:59,455] ERROR [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Could not find offset index file corresponding to log file E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-01-27 15:50:59,455] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,481] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 152 (kafka.log.ProducerStateManager)
[2020-01-27 15:50:59,486] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 152 (kafka.log.Log)
[2020-01-27 15:50:59,487] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 152 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,498] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000152.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:50:59,507] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 156 (kafka.log.ProducerStateManager)
[2020-01-27 15:50:59,609] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 156 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,612] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000156.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:50:59,613] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 2 segments, log start offset 0 and log end offset 156 in 185 ms (kafka.log.Log)
[2020-01-27 15:50:59,625] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:59,626] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,646] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,648] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-01-27 15:50:59,653] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:59,653] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,662] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,664] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-01-27 15:50:59,678] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:59,681] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,692] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,694] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:50:59,707] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:59,708] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,719] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,721] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:50:59,730] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:59,733] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,744] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:50:59,746] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:50:59,760] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:50:59,761] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,308] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 38039 (kafka.log.ProducerStateManager)
[2020-01-27 15:51:00,544] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 38039 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,548] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-18\00000000000000038039.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:51:00,552] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 38039 in 796 ms (kafka.log.Log)
[2020-01-27 15:51:00,589] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,590] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,616] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,617] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2020-01-27 15:51:00,623] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,624] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,636] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,638] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:51:00,648] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,649] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,661] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,663] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:51:00,673] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,674] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,686] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,688] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-01-27 15:51:00,697] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,699] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,708] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,711] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:51:00,724] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,724] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,737] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,738] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-01-27 15:51:00,746] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,750] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,758] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,763] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:51:00,773] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,774] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,786] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,788] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:51:00,801] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,802] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,816] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,818] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:51:00,827] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,829] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,841] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,843] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:51:00,857] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,858] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,875] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,877] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:51:00,881] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:00,882] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:00,902] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 1596 (kafka.log.ProducerStateManager)
[2020-01-27 15:51:01,091] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1596 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,096] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-29\00000000000000001596.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:51:01,101] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 1596 in 222 ms (kafka.log.Log)
[2020-01-27 15:51:01,129] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,130] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,155] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,159] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2020-01-27 15:51:01,169] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,170] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,181] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,183] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:51:01,195] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,196] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,212] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,217] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:51:01,225] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,226] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,240] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,242] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:51:01,246] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,246] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,255] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,257] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-01-27 15:51:01,267] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,270] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,290] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,294] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2020-01-27 15:51:01,317] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,317] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,334] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,340] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2020-01-27 15:51:01,360] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,362] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,382] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,384] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2020-01-27 15:51:01,398] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,399] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,419] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,422] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:51:01,434] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,435] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,452] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,455] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-01-27 15:51:01,471] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,472] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,494] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,498] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-01-27 15:51:01,516] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,517] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,537] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,544] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2020-01-27 15:51:01,561] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,563] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,587] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,594] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2020-01-27 15:51:01,607] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,608] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,631] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,633] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-01-27 15:51:01,649] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,650] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,668] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,670] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-01-27 15:51:01,676] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,681] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,692] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,695] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:51:01,704] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,705] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,716] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,718] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:51:01,726] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,729] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,740] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,741] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:51:01,753] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,754] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,764] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,767] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:51:01,776] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,777] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,787] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,789] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:51:01,796] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,798] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,812] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-01-27 15:51:01,881] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,883] INFO [ProducerStateManager partition=__consumer_offsets-48] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-48\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:51:01,885] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 93 ms (kafka.log.Log)
[2020-01-27 15:51:01,897] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,897] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,910] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,913] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:51:01,922] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,923] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,948] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,949] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-01-27 15:51:01,956] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,956] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,981] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:01,983] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-01-27 15:51:01,989] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:01,990] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:02,015] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:02,016] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-01-27 15:51:02,025] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:02,028] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:02,050] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:02,052] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:51:02,060] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:51:02,061] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:02,081] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:51:02,082] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-01-27 15:51:02,089] INFO Logs loading complete in 3789 ms. (kafka.log.LogManager)
[2020-01-27 15:51:02,121] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-01-27 15:51:02,126] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-01-27 15:51:02,519] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:497)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2267)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2267)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2267)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:604)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
	Suppressed: java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned -> E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-01-27 15:51:02,670] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:51:02,834] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-01-27 15:51:02,943] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:51:02,994] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-01-27 15:51:02,998] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-01-27 15:51:03,061] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:51:03,063] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:51:03,065] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:51:03,064] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:51:03,077] ERROR Failed to clean up log for __consumer_offsets-12 in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2544)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:445)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:557)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:529)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:528)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:528)
	at kafka.log.Cleaner.clean(LogCleaner.scala:502)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:371)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:344)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:324)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:313)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-01-27 15:51:03,100] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-01-27 15:51:03,104] INFO [ReplicaManager broker=0] Stopping serving replicas in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.server.ReplicaManager)
[2020-01-27 15:51:03,127] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka. (kafka.server.ReplicaManager)
[2020-01-27 15:51:03,131] INFO Stopping serving logs in dir E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka (kafka.log.LogManager)
[2020-01-27 15:51:03,143] ERROR Shutdown broker because all log dirs in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka have failed (kafka.log.LogManager)
[2020-01-27 15:51:03,500] WARN Exception causing close of session 0x100001b0ae50001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-01-27 15:51:11,145] INFO Expiring session 0x100001b0ae50001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:42,272] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:52:42,273] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:52:42,276] INFO clientPortAddress is 0.0.0.0/0.0.0.0:7777 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:52:42,276] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:52:42,278] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-01-27 15:52:42,279] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-01-27 15:52:42,279] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-01-27 15:52:42,279] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-01-27 15:52:42,280] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-01-27 15:52:42,301] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:52:42,301] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:52:42,302] INFO clientPortAddress is 0.0.0.0/0.0.0.0:7777 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:52:42,302] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-27 15:52:42,302] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-01-27 15:52:42,306] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-01-27 15:52:46,867] INFO Server environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,868] INFO Server environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,869] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,869] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,870] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,870] INFO Server environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,879] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,893] INFO Server environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,895] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,897] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,898] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,899] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,901] INFO Server environment:user.name=Administrator (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,902] INFO Server environment:user.home=C:\Users\Administrator (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,906] INFO Server environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,912] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,913] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,913] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,918] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,925] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,927] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2 snapdir E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-01-27 15:52:46,948] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-01-27 15:52:46,956] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-01-27 15:52:46,974] INFO binding to port 0.0.0.0/0.0.0.0:7777 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-01-27 15:52:46,997] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-01-27 15:52:47,003] INFO Reading snapshot E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2\snapshot.1a4 (org.apache.zookeeper.server.persistence.FileSnap)
[2020-01-27 15:52:47,041] INFO Snapshotting: 0x1c2 to E:\krishna\kafka\kafka_2.12-2.4.0\data\zookeeper\version-2\snapshot.1c2 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-01-27 15:52:47,087] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-01-27 15:52:57,555] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-01-27 15:52:58,335] INFO starting (kafka.server.KafkaServer)
[2020-01-27 15:52:58,336] INFO Connecting to zookeeper on localhost:7777 (kafka.server.KafkaServer)
[2020-01-27 15:52:58,363] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:7777. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:53:03,498] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,498] INFO Client environment:host.name=DESKTOP-AHJN3HV (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,498] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,499] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,499] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_181\jre (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,499] INFO Client environment:java.class.path=E:\krishna\kafka\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\argparse4j-0.7.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\audience-annotations-0.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-cli-1.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\commons-lang3-3.8.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-api-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-file-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-json-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-mirror-client-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-runtime-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\connect-transforms-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\guava-20.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-api-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-locator-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\hk2-utils-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-core-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-databind-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jackson-module-scala_2.12-2.10.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.activation-api-1.2.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.inject-2.5.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javassist-3.22.0-CR2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.servlet-api-3.1.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jaxb-api-2.3.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-client-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-common-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-container-servlet-core-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-hk2-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-media-jaxb-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jersey-server-2.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\jopt-simple-5.0.4.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-clients-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-examples-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-scala_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka-tools-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-javadoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-scaladoc.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test-sources.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0-test.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\kafka_2.12-2.4.0.jar.asc;E:\krishna\kafka\kafka_2.12-2.4.0\libs\log4j-1.2.17.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\lz4-java-1.6.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\maven-artifact-3.6.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\metrics-core-2.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-buffer-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-codec-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-handler-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-resolver-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\osgi-resource-locator-1.0.1.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\paranamer-2.8.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\plexus-utils-3.2.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\reflections-0.9.11.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\rocksdbjni-5.18.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-collection-compat_2.12-2.1.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-java8-compat_2.12-0.9.0.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-library-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-logging_2.12-3.9.2.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\scala-reflect-2.12.10.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-api-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\slf4j-log4j12-1.7.28.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\snappy-java-1.1.7.3.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\validation-api-2.0.1.Final.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zookeeper-jute-3.5.6.jar;E:\krishna\kafka\kafka_2.12-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,500] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_181\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\app\Administrator\product\11.2.0\dbhome_1\bin;C:\Program Files\Java\jdk1.8.0_181\bin;C:\Program Files\Java\jre1.8.0_181\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\PuTTY\;E:\krishna\Softwares\apache-maven-3.6.1-bin\apache-maven-3.6.1\bin;C:\Program Files\MongoDB\Server\4.0\bin;C:\Program Files (x86)\Microsoft VS Code\bin;C:\Program Files\nodejs\;C:\Windows\System32;C:\Windows\System32\wbem;E:\krishna\13-Aug-19\apache-ant-1.10.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MySQL\MySQL Server 8.0\bin;E:\krishna\kafka\kafka_2.12-2.4.0\bin\windows;C:\Program Files\Git\cmd;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\ProgramData\Administrator\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\GitHubDesktop\bin;C:\Users\Administrator\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\Administrator\AppData\Roaming\npm;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.2.2\bin;;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;;C:\Program Files\Docker Toolbox;. (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,501] INFO Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,501] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,502] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,503] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,504] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,504] INFO Client environment:user.name=Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,505] INFO Client environment:user.home=C:\Users\Administrator (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,506] INFO Client environment:user.dir=E:\krishna\kafka\kafka_2.12-2.4.0 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,507] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,519] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,525] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,530] INFO Initiating client connection, connectString=localhost:7777 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2ef3eef9 (org.apache.zookeeper.ZooKeeper)
[2020-01-27 15:53:03,544] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-01-27 15:53:03,568] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-01-27 15:53:03,591] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:53:03,597] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:53:03,627] INFO Opening socket connection to server localhost/127.0.0.1:7777. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:53:03,636] INFO Socket connection established, initiating session, client: /127.0.0.1:3711, server: localhost/127.0.0.1:7777 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:53:03,651] INFO Creating new log file: log.1c3 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-01-27 15:53:03,806] INFO Session establishment complete on server localhost/127.0.0.1:7777, sessionid = 0x10000221a200000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-01-27 15:53:03,818] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-01-27 15:53:04,638] INFO Cluster ID = ZCBoZNizRZu31bPjkZIQkw (kafka.server.KafkaServer)
[2020-01-27 15:53:04,755] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:53:04,786] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = E:/krishna/kafka/kafka_2.12-2.4.0/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:7777
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-01-27 15:53:04,840] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:53:04,840] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:53:04,844] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-01-27 15:53:04,916] INFO Loading logs. (kafka.log.LogManager)
[2020-01-27 15:53:05,025] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 7 (kafka.log.Log)
[2020-01-27 15:53:05,030] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,060] INFO [ProducerStateManager partition=first-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-01-27 15:53:05,178] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,197] INFO [Log partition=first-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 7 and log end offset 7 in 218 ms (kafka.log.Log)
[2020-01-27 15:53:05,254] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:53:05,258] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,268] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:53:05,293] INFO [ProducerStateManager partition=first_topic-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-01-27 15:53:05,412] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,422] INFO [ProducerStateManager partition=first_topic-1] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:53:05,460] INFO [Log partition=first_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 5 in 211 ms (kafka.log.Log)
[2020-01-27 15:53:05,487] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 4 (kafka.log.Log)
[2020-01-27 15:53:05,488] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,494] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-01-27 15:53:05,508] INFO [ProducerStateManager partition=first_topic-2] Writing producer snapshot at offset 13 (kafka.log.ProducerStateManager)
[2020-01-27 15:53:05,580] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 13 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,590] INFO [ProducerStateManager partition=first_topic-2] Loading producer state from snapshot file 'E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-2\00000000000000000013.snapshot' (kafka.log.ProducerStateManager)
[2020-01-27 15:53:05,594] INFO [Log partition=first_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 4 and log end offset 13 in 114 ms (kafka.log.Log)
[2020-01-27 15:53:05,620] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 1 (kafka.log.Log)
[2020-01-27 15:53:05,621] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,627] INFO [ProducerStateManager partition=second-topic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-01-27 15:53:05,653] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,656] INFO [Log partition=second-topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 1 and log end offset 1 in 41 ms (kafka.log.Log)
[2020-01-27 15:53:05,665] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:53:05,666] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,687] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,689] INFO [Log partition=second_topic-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:53:05,696] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Recovering unflushed segment 0 (kafka.log.Log)
[2020-01-27 15:53:05,696] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,707] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:05,710] INFO [Log partition=second_topic-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:53:05,721] INFO Logs loading complete in 805 ms. (kafka.log.LogManager)
[2020-01-27 15:53:05,743] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-01-27 15:53:05,746] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-01-27 15:53:06,268] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-01-27 15:53:06,319] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-01-27 15:53:06,322] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-01-27 15:53:06,370] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:53:06,375] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:53:06,376] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:53:06,387] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:53:06,432] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-01-27 15:53:11,129] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-01-27 15:53:11,517] INFO Stat of the created znode at /brokers/ids/0 is: 465,465,1580120591228,1580120591228,1,0,0,72057740505120768,200,0,465
 (kafka.zk.KafkaZkClient)
[2020-01-27 15:53:11,519] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-AHJN3HV,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 465 (kafka.zk.KafkaZkClient)
[2020-01-27 15:53:11,998] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:53:12,009] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:53:12,011] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:53:12,163] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-01-27 15:53:12,180] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-01-27 15:53:12,231] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 51 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:12,295] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:8000,blockEndProducerId:8999) by writing to Zk with path version 9 (kafka.coordinator.transaction.ProducerIdManager)
[2020-01-27 15:53:12,337] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-01-27 15:53:12,344] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-01-27 15:53:12,345] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-01-27 15:53:12,609] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-01-27 15:53:12,690] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-01-27 15:53:12,829] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-01-27 15:53:12,863] INFO Kafka version: 2.4.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-01-27 15:53:12,867] INFO Kafka commitId: 77a89fcf8d7fa018 (org.apache.kafka.common.utils.AppInfoParser)
[2020-01-27 15:53:12,868] INFO Kafka startTimeMs: 1580120592833 (org.apache.kafka.common.utils.AppInfoParser)
[2020-01-27 15:53:12,881] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-01-27 15:53:13,101] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, first_topic-2, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, second_topic-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, first_topic-1, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, second_topic-2, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, second-topic-0, first_topic-0, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, second_topic-1, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, first-topic-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-01-27 15:53:13,164] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:13,168] INFO [Log partition=__consumer_offsets-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-01-27 15:53:13,171] INFO Created log for partition __consumer_offsets-0 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:13,186] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:13,197] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:13,431] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:13,436] INFO [Log partition=__consumer_offsets-48, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2020-01-27 15:53:13,439] INFO Created log for partition __consumer_offsets-48 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:13,444] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:13,455] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:13,550] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:13,555] INFO [Log partition=__consumer_offsets-29, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-01-27 15:53:13,560] INFO Created log for partition __consumer_offsets-29 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:13,564] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:13,576] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:13,650] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:13,653] INFO [Log partition=__consumer_offsets-10, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:53:13,655] INFO Created log for partition __consumer_offsets-10 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:13,661] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:13,662] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:13,748] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:13,756] INFO [Log partition=first_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:53:13,762] INFO Created log for partition first_topic-0 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\first_topic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:13,764] INFO [Partition first_topic-0 broker=0] Log loaded for partition first_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:13,764] INFO [Partition first_topic-0 broker=0] first_topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:13,858] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:13,862] INFO [Log partition=__consumer_offsets-45, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:53:13,865] INFO Created log for partition __consumer_offsets-45 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:13,871] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:13,885] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:13,964] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:13,966] INFO [Log partition=__consumer_offsets-26, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-01-27 15:53:13,969] INFO Created log for partition __consumer_offsets-26 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:13,975] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:13,980] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:14,059] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:14,061] INFO [Log partition=__consumer_offsets-7, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:53:14,063] INFO Created log for partition __consumer_offsets-7 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:14,069] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:14,070] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:14,178] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:14,182] INFO [Log partition=__consumer_offsets-42, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-01-27 15:53:14,187] INFO Created log for partition __consumer_offsets-42 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:14,191] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:14,200] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:14,254] INFO [Partition second_topic-1 broker=0] Log loaded for partition second_topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:14,255] INFO [Partition second_topic-1 broker=0] second_topic-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:14,334] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:14,336] INFO [Log partition=__consumer_offsets-4, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-01-27 15:53:14,339] INFO Created log for partition __consumer_offsets-4 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:14,346] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:14,355] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:14,433] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:14,435] INFO [Log partition=__consumer_offsets-23, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-01-27 15:53:14,438] INFO Created log for partition __consumer_offsets-23 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:14,444] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:14,454] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:14,623] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:14,625] INFO [Log partition=__consumer_offsets-1, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-01-27 15:53:14,633] INFO Created log for partition __consumer_offsets-1 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:14,634] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:14,637] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:14,724] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:14,729] INFO [Log partition=__consumer_offsets-39, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:53:14,734] INFO Created log for partition __consumer_offsets-39 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:14,734] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:14,735] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:14,802] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:14,803] INFO [Log partition=__consumer_offsets-20, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-01-27 15:53:14,807] INFO Created log for partition __consumer_offsets-20 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:14,814] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:14,823] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:14,897] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:14,899] INFO [Log partition=__consumer_offsets-17, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:53:14,900] INFO Created log for partition __consumer_offsets-17 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:14,907] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:14,911] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:15,202] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:15,204] INFO [Log partition=__consumer_offsets-36, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2020-01-27 15:53:15,206] INFO Created log for partition __consumer_offsets-36 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:15,212] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:15,213] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:15,428] INFO [Partition first_topic-1 broker=0] Log loaded for partition first_topic-1 with initial high watermark 5 (kafka.cluster.Partition)
[2020-01-27 15:53:15,429] INFO [Partition first_topic-1 broker=0] first_topic-1 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:15,472] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:15,476] INFO [Log partition=__consumer_offsets-14, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-01-27 15:53:15,485] INFO Created log for partition __consumer_offsets-14 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:15,487] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:15,497] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:15,565] INFO [Partition second_topic-2 broker=0] Log loaded for partition second_topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:15,566] INFO [Partition second_topic-2 broker=0] second_topic-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:15,643] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:15,646] INFO [Log partition=__consumer_offsets-33, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:53:15,648] INFO Created log for partition __consumer_offsets-33 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:15,654] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:15,665] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:15,744] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:15,748] INFO [Log partition=__consumer_offsets-49, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:53:15,750] INFO Created log for partition __consumer_offsets-49 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:15,755] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:15,756] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:15,837] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:15,839] INFO [Log partition=__consumer_offsets-11, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-01-27 15:53:15,841] INFO Created log for partition __consumer_offsets-11 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:15,848] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:15,852] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:16,060] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:16,063] INFO [Log partition=__consumer_offsets-30, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:53:16,065] INFO Created log for partition __consumer_offsets-30 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:16,072] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:16,081] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:16,156] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:16,159] INFO [Log partition=__consumer_offsets-46, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-01-27 15:53:16,161] INFO Created log for partition __consumer_offsets-46 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:16,168] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:16,181] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:16,274] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:16,277] INFO [Log partition=__consumer_offsets-27, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-01-27 15:53:16,283] INFO Created log for partition __consumer_offsets-27 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:16,287] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:16,301] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:16,379] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:16,381] INFO [Log partition=__consumer_offsets-8, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-01-27 15:53:16,383] INFO Created log for partition __consumer_offsets-8 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:16,393] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:16,396] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:16,501] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:16,505] INFO [Log partition=__consumer_offsets-24, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:53:16,512] INFO Created log for partition __consumer_offsets-24 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:16,515] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:16,531] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:16,854] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:16,858] INFO [Log partition=__consumer_offsets-43, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-01-27 15:53:16,866] INFO Created log for partition __consumer_offsets-43 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:16,873] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:16,875] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,070] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:17,073] INFO [Log partition=__consumer_offsets-5, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-01-27 15:53:17,082] INFO Created log for partition __consumer_offsets-5 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:17,084] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:17,085] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,156] INFO [Partition second-topic-0 broker=0] Log loaded for partition second-topic-0 with initial high watermark 1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,156] INFO [Partition second-topic-0 broker=0] second-topic-0 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,224] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:17,226] INFO [Log partition=__consumer_offsets-21, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-01-27 15:53:17,229] INFO Created log for partition __consumer_offsets-21 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:17,235] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:17,239] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,317] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:17,320] INFO [Log partition=__consumer_offsets-2, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-01-27 15:53:17,322] INFO Created log for partition __consumer_offsets-2 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:17,328] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:17,329] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,410] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:17,413] INFO [Log partition=__consumer_offsets-40, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-01-27 15:53:17,415] INFO Created log for partition __consumer_offsets-40 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:17,421] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:17,422] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,509] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:17,514] INFO [Log partition=__consumer_offsets-37, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-01-27 15:53:17,517] INFO Created log for partition __consumer_offsets-37 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:17,521] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:17,532] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,593] INFO [Partition first_topic-2 broker=0] Log loaded for partition first_topic-2 with initial high watermark 13 (kafka.cluster.Partition)
[2020-01-27 15:53:17,594] INFO [Partition first_topic-2 broker=0] first_topic-2 starts at Leader Epoch 0 from offset 13. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,620] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:17,626] INFO [Log partition=__consumer_offsets-18, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:53:17,638] INFO Created log for partition __consumer_offsets-18 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:17,641] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:17,653] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,768] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:17,771] INFO [Log partition=__consumer_offsets-34, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-01-27 15:53:17,779] INFO Created log for partition __consumer_offsets-34 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:17,781] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:17,797] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:17,929] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:17,933] INFO [Log partition=__consumer_offsets-15, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-01-27 15:53:17,936] INFO Created log for partition __consumer_offsets-15 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:17,942] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:17,943] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:18,110] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:18,115] INFO [Log partition=__consumer_offsets-12, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-01-27 15:53:18,118] INFO Created log for partition __consumer_offsets-12 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:18,124] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:18,134] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:18,338] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:18,340] INFO [Log partition=__consumer_offsets-31, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-01-27 15:53:18,342] INFO Created log for partition __consumer_offsets-31 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:18,349] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:18,352] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:18,532] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:18,534] INFO [Log partition=second_topic-0, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-01-27 15:53:18,536] INFO Created log for partition second_topic-0 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\second_topic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:18,542] INFO [Partition second_topic-0 broker=0] Log loaded for partition second_topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:18,543] INFO [Partition second_topic-0 broker=0] second_topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:18,614] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:18,616] INFO [Log partition=__consumer_offsets-9, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-01-27 15:53:18,618] INFO Created log for partition __consumer_offsets-9 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:18,624] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:18,625] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:18,696] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:18,698] INFO [Log partition=__consumer_offsets-47, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-01-27 15:53:18,701] INFO Created log for partition __consumer_offsets-47 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:18,707] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:18,708] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:18,787] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:18,793] INFO [Log partition=__consumer_offsets-19, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-01-27 15:53:18,801] INFO Created log for partition __consumer_offsets-19 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:18,802] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:18,807] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:19,088] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:19,092] INFO [Log partition=__consumer_offsets-28, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-01-27 15:53:19,099] INFO Created log for partition __consumer_offsets-28 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:19,104] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:19,119] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:19,292] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:19,296] INFO [Log partition=__consumer_offsets-38, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-01-27 15:53:19,300] INFO Created log for partition __consumer_offsets-38 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:19,306] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:19,316] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:19,387] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:19,389] INFO [Log partition=__consumer_offsets-35, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-01-27 15:53:19,396] INFO Created log for partition __consumer_offsets-35 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:19,397] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:19,398] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:19,482] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:19,484] INFO [Log partition=__consumer_offsets-44, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-01-27 15:53:19,486] INFO Created log for partition __consumer_offsets-44 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:19,493] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:19,497] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:19,574] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:19,577] INFO [Log partition=__consumer_offsets-6, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-01-27 15:53:19,579] INFO Created log for partition __consumer_offsets-6 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:19,585] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:19,586] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:19,663] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:19,665] INFO [Log partition=__consumer_offsets-25, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-01-27 15:53:19,667] INFO Created log for partition __consumer_offsets-25 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:19,674] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:19,677] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:19,745] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:19,747] INFO [Log partition=__consumer_offsets-16, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-01-27 15:53:19,748] INFO Created log for partition __consumer_offsets-16 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:19,755] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:19,756] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:19,822] INFO [Partition first-topic-0 broker=0] Log loaded for partition first-topic-0 with initial high watermark 7 (kafka.cluster.Partition)
[2020-01-27 15:53:19,822] INFO [Partition first-topic-0 broker=0] first-topic-0 starts at Leader Epoch 0 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:19,894] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:19,897] INFO [Log partition=__consumer_offsets-22, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-01-27 15:53:19,899] INFO Created log for partition __consumer_offsets-22 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:19,905] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:19,915] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:19,981] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:19,984] INFO [Log partition=__consumer_offsets-41, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-01-27 15:53:19,985] INFO Created log for partition __consumer_offsets-41 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:19,992] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:20,002] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:20,071] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:20,076] INFO [Log partition=__consumer_offsets-32, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-01-27 15:53:20,080] INFO Created log for partition __consumer_offsets-32 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:20,083] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:20,088] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:20,165] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:20,166] INFO [Log partition=__consumer_offsets-3, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-01-27 15:53:20,170] INFO Created log for partition __consumer_offsets-3 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:20,176] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:20,190] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:20,270] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-01-27 15:53:20,272] INFO [Log partition=__consumer_offsets-13, dir=E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-01-27 15:53:20,274] INFO Created log for partition __consumer_offsets-13 in E:\krishna\kafka\kafka_2.12-2.4.0\data\kafka\__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-01-27 15:53:20,280] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-01-27 15:53:20,281] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-01-27 15:53:20,396] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,400] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,406] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,412] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 17 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,430] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,436] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,449] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,456] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,461] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,467] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,479] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,483] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,492] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,498] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,505] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,510] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,516] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,518] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,529] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,539] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,547] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,557] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,565] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,580] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,582] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,584] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,594] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,601] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,609] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,620] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,622] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,625] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,640] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,648] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,663] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,670] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,687] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,681] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,696] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,707] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,713] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,729] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,735] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,747] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,754] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,763] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,770] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,780] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,783] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,794] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,808] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,812] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,821] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,826] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,834] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,847] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,880] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,884] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,893] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,896] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,906] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,909] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,916] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,918] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,908] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,929] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,932] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,942] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,944] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,956] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,952] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,963] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,964] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,964] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,968] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,977] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:20,988] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,012] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,000] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,016] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,017] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,025] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,036] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,041] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,042] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,051] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,071] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,079] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,091] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 15:53:21,105] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 16:03:02,415] INFO [GroupCoordinator 0]: Preparing to rebalance group my-fourth-application in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-1-ca4b8e80-f36e-4fa5-ad77-9123f970f063 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-01-27 16:03:02,460] INFO [GroupCoordinator 0]: Stabilized group my-fourth-application generation 1 (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2020-01-27 16:03:02,481] INFO [GroupCoordinator 0]: Assignment received from leader for group my-fourth-application for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-01-27 16:03:12,180] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 16:13:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 16:23:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 16:33:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 16:43:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 16:53:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 17:03:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 17:13:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 17:23:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 17:33:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 17:43:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 17:53:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 18:03:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 18:13:12,179] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 18:23:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 18:33:12,176] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 18:43:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 18:53:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 19:03:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 19:13:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 19:23:12,173] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 19:33:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 19:43:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 19:53:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 20:03:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 20:13:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 20:23:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 20:33:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 20:43:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 20:53:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 21:03:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 21:13:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 21:23:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 21:33:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 21:43:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 21:53:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 22:03:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 22:13:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 22:23:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 22:33:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 22:43:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 22:53:12,182] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 23:03:12,177] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 23:13:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 23:23:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 23:33:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 23:43:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-27 23:53:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-28 00:03:12,175] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-28 00:13:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-28 00:23:12,176] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-01-28 00:33:12,174] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
